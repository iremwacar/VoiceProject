{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model başarıyla yüklendi.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Modeli kaydetme\n",
    "model_filename = r\"..\\Model\\random_forest_model.joblib\"\n",
    "\n",
    "# Modeli yükleme\n",
    "loaded_model = joblib.load(model_filename)\n",
    "print(\"Model başarıyla yüklendi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tahmin edilen etiket: irem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iremm\\.conda\\envs\\BTK-AI\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\iremm\\.conda\\envs\\BTK-AI\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Scaler ve model dosyalarını yükleme\n",
    "scaler_filename = '..\\\\Model\\\\scaler.joblib'  # Modelin scaler dosyasının yolu\n",
    "model_filename = '..\\\\Model\\\\random_forest_model.joblib'  # Model dosyasının yolu\n",
    "\n",
    "scaler = joblib.load(scaler_filename)\n",
    "model = joblib.load(model_filename)\n",
    "\n",
    "def extract_features_for_prediction(file_path):\n",
    "    \"\"\"Ses dosyasından özellikleri çıkar.\"\"\"\n",
    "    try:\n",
    "        # Ses dosyasını yükle\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # MFCC (Mel-frequency cepstral coefficients) çıkarımı\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        mfcc_mean = np.mean(mfcc, axis=1)\n",
    "\n",
    "        # Chroma çıkarımı (müzikal tonlar)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        chroma_mean = np.mean(chroma, axis=1)\n",
    "\n",
    "        # RMS Energy çıkarımı\n",
    "        rms = librosa.feature.rms(y=y)\n",
    "        rms_mean = np.mean(rms)\n",
    "\n",
    "        # Zero-Crossing Rate çıkarımı\n",
    "        zcr = librosa.feature.zero_crossing_rate(y=y)\n",
    "        zcr_mean = np.mean(zcr)\n",
    "        \n",
    "        # Özellikleri birleştir\n",
    "        features = np.hstack((mfcc_mean, chroma_mean, rms_mean, zcr_mean))\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def predict_audio_with_scaler(file_path):\n",
    "    \"\"\"Ses dosyasını scaler ve model ile test et.\"\"\"\n",
    "    # Özellik çıkarma\n",
    "    features = extract_features_for_prediction(file_path)\n",
    "    if features is None:\n",
    "        print(\"Özellik çıkarma başarısız.\")\n",
    "        return\n",
    "\n",
    "    # Özellikleri normalize et\n",
    "    features = features.reshape(1, -1)  # Modelin tahmin yapabilmesi için 2D array haline getir\n",
    "    normalized_features = scaler.transform(features)\n",
    "\n",
    "    # Model ile tahmin yap\n",
    "    prediction = model.predict(normalized_features)\n",
    "    print(f\"Tahmin edilen etiket: {prediction[0]}\")\n",
    "\n",
    "# Test edilecek ses dosyası\n",
    "test_file = \"C:\\\\VoiceProject\\\\Voice\\\\irem\\\\korku\\\\Iremkorku3.wav\"  # Test ses dosyasının tam yolunu yazın\n",
    "predict_audio_with_scaler(test_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Model/scaler_model.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Model/random_forest_model.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Scaler'ı yükleyin (eğitilmiş scaler modelinin yolunu belirtin)\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m scaler \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../Model/scaler_model.joblib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Özellik çıkarma fonksiyonu\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features_from_audio\u001b[39m(audio_data, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\iremm\\.conda\\envs\\BTK-AI\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Model/scaler_model.joblib'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import librosa\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import logging\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "app = Flask(__name__, template_folder='../Frontend')\n",
    "\n",
    "# Modeli yükleyin (eğitilmiş modelinizin yolunu belirtin)\n",
    "model = joblib.load(\"../Model/random_forest_model.joblib\")\n",
    "\n",
    "# Scaler'ı yükleyin (eğitilmiş scaler modelinin yolunu belirtin)\n",
    "scaler = joblib.load(\"../Model/scaler_model.joblib\")\n",
    "\n",
    "# Özellik çıkarma fonksiyonu\n",
    "def extract_features_from_audio(audio_data, sr=16000):\n",
    "    try:\n",
    "        # MFCC çıkarımı\n",
    "        mfcc = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)\n",
    "        mfcc_mean = np.mean(mfcc, axis=1)  # MFCC ortalamasını al\n",
    "\n",
    "        # Chroma çıkarımı\n",
    "        chroma = librosa.feature.chroma_stft(y=audio_data, sr=sr)\n",
    "        chroma_mean = np.mean(chroma, axis=1)\n",
    "\n",
    "        # RMS Energy çıkarımı\n",
    "        rms = librosa.feature.rms(y=audio_data)\n",
    "        rms_mean = np.mean(rms)\n",
    "\n",
    "        # Zero-Crossing Rate çıkarımı\n",
    "        zcr = librosa.feature.zero_crossing_rate(y=audio_data)\n",
    "        zcr_mean = np.mean(zcr)\n",
    "        \n",
    "        # Özellikleri birleştir\n",
    "        features = np.hstack((mfcc_mean, chroma_mean, rms_mean, zcr_mean))\n",
    "        return features\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio: {e}\")\n",
    "        return None\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    # Ana sayfayı (HTML formunu) kullanıcıya göster\n",
    "    return render_template('index.html')\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Ses dosyasını alın\n",
    "    audio_file = request.files['file']\n",
    "    \n",
    "    logging.debug(f\"Dosya alındı: {audio_file.filename}\")\n",
    "    \n",
    "    # Geçici bir dosyaya kaydedin\n",
    "    temp_file_path = os.path.join('uploads', audio_file.filename)\n",
    "    try:\n",
    "        audio_file.save(temp_file_path)\n",
    "        logging.debug(f\"Dosya kaydedildi: {temp_file_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Dosya kaydedilemedi: {e}\")\n",
    "        return jsonify({\"error\": f\"Dosya kaydedilemedi: {e}\"}), 500\n",
    "\n",
    "    try:\n",
    "        # Ses dosyasını yükleyin\n",
    "        audio_data, sr = librosa.load(temp_file_path, sr=None)\n",
    "        logging.debug(f\"Ses dosyası başarıyla yüklendi. Örnekleme hızı: {sr}Hz\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ses dosyası yüklenemedi: {e}\")\n",
    "        return jsonify({\"error\": f\"Ses dosyası yüklenemedi: {e}\"}), 500\n",
    "\n",
    "    # 1. Adım: Ses verisini 0-1 arasına normalize etme\n",
    "    audio_data = (audio_data - np.min(audio_data)) / (np.max(audio_data) - np.min(audio_data))  # 0-1 arası\n",
    "\n",
    "    # 2. Adım: Özellik çıkarımı\n",
    "    features = extract_features_from_audio(audio_data)\n",
    "    if features is None:\n",
    "        return jsonify({\"error\": \"Ses dosyası işlenemedi.\"}), 500\n",
    "\n",
    "    logging.debug(f\"Özellikler çıkarıldı: {features}\")\n",
    "\n",
    "    # 3. Adım: Özellikleri normalize etme\n",
    "    try:\n",
    "        normalized_features = scaler.transform([features])\n",
    "        logging.debug(f\"Normalize edilmiş özellikler: {normalized_features}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Özellikler normalleştirilemedi: {e}\")\n",
    "        return jsonify({\"error\": f\"Özellikler normalleştirilemedi: {e}\"}), 500\n",
    "\n",
    "    # 4. Adım: Model ile tahmin yapma\n",
    "    try:\n",
    "        prediction = model.predict(normalized_features)\n",
    "        logging.debug(f\"Tahmin yapıldı: {prediction}\")\n",
    "        return jsonify({\"prediction\": prediction[0]})\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Tahmin yapılamadı: {e}\")\n",
    "        return jsonify({\"error\": f\"Tahmin yapılamadı: {e}\"}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BTK-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
