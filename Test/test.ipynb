{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model başarıyla yüklendi.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Modeli kaydetme\n",
    "model_filename = r\"..\\Model\\random_forest_model.joblib\"\n",
    "\n",
    "# Modeli yükleme\n",
    "loaded_model = joblib.load(model_filename)\n",
    "print(\"Model başarıyla yüklendi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tahmin edilen etiket: irem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iremm\\.conda\\envs\\BTK-AI\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Scaler ve model dosyalarını yükleme\n",
    "scaler_filename = '..\\\\Model\\\\scaler.joblib'  # Modelin scaler dosyasının yolu\n",
    "model_filename = '..\\\\Model\\\\random_forest_model.joblib'  # Model dosyasının yolu\n",
    "\n",
    "scaler = joblib.load(scaler_filename)\n",
    "model = joblib.load(model_filename)\n",
    "\n",
    "def extract_features_for_prediction(file_path):\n",
    "    \"\"\"Ses dosyasından özellikleri çıkar.\"\"\"\n",
    "    try:\n",
    "        # Ses dosyasını yükle\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # MFCC (Mel-frequency cepstral coefficients) çıkarımı\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        mfcc_mean = np.mean(mfcc, axis=1)\n",
    "\n",
    "        # Chroma çıkarımı (müzikal tonlar)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        chroma_mean = np.mean(chroma, axis=1)\n",
    "\n",
    "        # RMS Energy çıkarımı\n",
    "        rms = librosa.feature.rms(y=y)\n",
    "        rms_mean = np.mean(rms)\n",
    "\n",
    "        # Zero-Crossing Rate çıkarımı\n",
    "        zcr = librosa.feature.zero_crossing_rate(y=y)\n",
    "        zcr_mean = np.mean(zcr)\n",
    "        \n",
    "        # Özellikleri birleştir\n",
    "        features = np.hstack((mfcc_mean, chroma_mean, rms_mean, zcr_mean))\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def predict_audio_with_scaler(file_path):\n",
    "    \"\"\"Ses dosyasını scaler ve model ile test et.\"\"\"\n",
    "    # Özellik çıkarma\n",
    "    features = extract_features_for_prediction(file_path)\n",
    "    if features is None:\n",
    "        print(\"Özellik çıkarma başarısız.\")\n",
    "        return\n",
    "\n",
    "    # Özellikleri normalize et\n",
    "    features = features.reshape(1, -1)  # Modelin tahmin yapabilmesi için 2D array haline getir\n",
    "    normalized_features = scaler.transform(features)\n",
    "\n",
    "    # Model ile tahmin yap\n",
    "    prediction = model.predict(normalized_features)\n",
    "    print(f\"Tahmin edilen etiket: {prediction[0]}\")\n",
    "\n",
    "# Test edilecek ses dosyası\n",
    "test_file = \"C:\\\\VoiceProject\\\\Voice\\\\irem\\\\korku\\\\Iremkorku3.wav\"  # Test ses dosyasının tam yolunu yazın\n",
    "predict_audio_with_scaler(test_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ses kaydediliyor...\n",
      "Ses kaydı tamamlandı.\n",
      "Normalized Features: [[ 1.4385326   0.41547256  0.14244706  0.58976865  0.60860644  1.06585869\n",
      "   0.81974664  0.7084436   0.88331646  0.78442708  0.46620559  0.70392766\n",
      "   0.85344995  0.52587329  0.31204448  0.23396043  0.18220832  0.0877071\n",
      "   0.0553659   0.05551352  0.07892574  0.16027521  0.5353755   1.18515853\n",
      "   0.69448006  4.81318403 -0.07128268]]\n",
      "Tahmin edilen sınıf: irem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iremm\\.conda\\envs\\BTK-AI\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import librosa\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import logging\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "app = Flask(__name__, template_folder='../Frontend')\n",
    "\n",
    "# Modeli yükleyin (eğitilmiş modelinizin yolunu belirtin)\n",
    "model = joblib.load(\"../Model/random_forest_model.joblib\")\n",
    "\n",
    "# Scaler'ı yükleyin (eğitilmiş scaler modelinin yolunu belirtin)\n",
    "scaler = joblib.load(\"../Model/scaler_model.joblib\")\n",
    "\n",
    "# Özellik çıkarma fonksiyonu\n",
    "def extract_features_from_audio(audio_data, sr=16000):\n",
    "    try:\n",
    "        # MFCC çıkarımı\n",
    "        mfcc = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)\n",
    "        mfcc_mean = np.mean(mfcc, axis=1)  # MFCC ortalamasını al\n",
    "\n",
    "        # Chroma çıkarımı\n",
    "        chroma = librosa.feature.chroma_stft(y=audio_data, sr=sr)\n",
    "        chroma_mean = np.mean(chroma, axis=1)\n",
    "\n",
    "        # RMS Energy çıkarımı\n",
    "        rms = librosa.feature.rms(y=audio_data)\n",
    "        rms_mean = np.mean(rms)\n",
    "\n",
    "        # Zero-Crossing Rate çıkarımı\n",
    "        zcr = librosa.feature.zero_crossing_rate(y=audio_data)\n",
    "        zcr_mean = np.mean(zcr)\n",
    "        \n",
    "        # Özellikleri birleştir\n",
    "        features = np.hstack((mfcc_mean, chroma_mean, rms_mean, zcr_mean))\n",
    "        return features\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio: {e}\")\n",
    "        return None\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    # Ana sayfayı (HTML formunu) kullanıcıya göster\n",
    "    return render_template('index.html')\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Ses dosyasını alın\n",
    "    audio_file = request.files['file']\n",
    "    \n",
    "    logging.debug(f\"Dosya alındı: {audio_file.filename}\")\n",
    "    \n",
    "    # Geçici bir dosyaya kaydedin\n",
    "    temp_file_path = os.path.join('uploads', audio_file.filename)\n",
    "    try:\n",
    "        audio_file.save(temp_file_path)\n",
    "        logging.debug(f\"Dosya kaydedildi: {temp_file_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Dosya kaydedilemedi: {e}\")\n",
    "        return jsonify({\"error\": f\"Dosya kaydedilemedi: {e}\"}), 500\n",
    "\n",
    "    try:\n",
    "        # Ses dosyasını yükleyin\n",
    "        audio_data, sr = librosa.load(temp_file_path, sr=None)\n",
    "        logging.debug(f\"Ses dosyası başarıyla yüklendi. Örnekleme hızı: {sr}Hz\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ses dosyası yüklenemedi: {e}\")\n",
    "        return jsonify({\"error\": f\"Ses dosyası yüklenemedi: {e}\"}), 500\n",
    "\n",
    "    # 1. Adım: Ses verisini 0-1 arasına normalize etme\n",
    "    audio_data = (audio_data - np.min(audio_data)) / (np.max(audio_data) - np.min(audio_data))  # 0-1 arası\n",
    "\n",
    "    # 2. Adım: Özellik çıkarımı\n",
    "    features = extract_features_from_audio(audio_data)\n",
    "    if features is None:\n",
    "        return jsonify({\"error\": \"Ses dosyası işlenemedi.\"}), 500\n",
    "\n",
    "    logging.debug(f\"Özellikler çıkarıldı: {features}\")\n",
    "\n",
    "    # 3. Adım: Özellikleri normalize etme\n",
    "    try:\n",
    "        normalized_features = scaler.transform([features])\n",
    "        logging.debug(f\"Normalize edilmiş özellikler: {normalized_features}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Özellikler normalleştirilemedi: {e}\")\n",
    "        return jsonify({\"error\": f\"Özellikler normalleştirilemedi: {e}\"}), 500\n",
    "\n",
    "    # 4. Adım: Model ile tahmin yapma\n",
    "    try:\n",
    "        prediction = model.predict(normalized_features)\n",
    "        logging.debug(f\"Tahmin yapıldı: {prediction}\")\n",
    "        return jsonify({\"prediction\": prediction[0]})\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Tahmin yapılamadı: {e}\")\n",
    "        return jsonify({\"error\": f\"Tahmin yapılamadı: {e}\"}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BTK-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
