{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Speak now.\n",
      "Recording finished, processing...\n",
      "Feature vector length: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iremm\\.conda\\envs\\BTK-AI\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 51 features, but KNeighborsClassifier is expecting 52 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m features_normalized \u001b[38;5;241m=\u001b[39m features_normalized\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Modelle tahmin yapma\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_normalized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\iremm\\.conda\\envs\\BTK-AI\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:271\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\iremm\\.conda\\envs\\BTK-AI\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:825\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    823\u001b[0m         X \u001b[38;5;241m=\u001b[39m _check_precomputed(X)\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n",
      "File \u001b[1;32mc:\\Users\\iremm\\.conda\\envs\\BTK-AI\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\iremm\\.conda\\envs\\BTK-AI\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 51 features, but KNeighborsClassifier is expecting 52 features as input."
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import joblib\n",
    "import speech_recognition as sr\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Modeli yükleyin\n",
    "model = joblib.load('../Model/VoiceModel.pkl')  # Modelin bulunduğu path'i ayarlayın\n",
    "\n",
    "# Mikrofon için tanıyıcıyı başlatın\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Mikrofonla ses kaydedin\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Recording... Speak now.\")\n",
    "    recognizer.adjust_for_ambient_noise(source)  # Çevresel gürültüyü dikkate al\n",
    "    audio = recognizer.listen(source)  # Ses kaydını al\n",
    "    print(\"Recording finished, processing...\")\n",
    "\n",
    "# Ses verilerini baytlara çıkarın\n",
    "audio_data = audio.get_wav_data()\n",
    "\n",
    "# BytesIO kullanarak audio'yu librosa ile yükleyin\n",
    "audio_io = BytesIO(audio_data)\n",
    "audio, _ = librosa.load(audio_io, sr=16000)\n",
    "\n",
    "# Özellikleri çıkartma (MFCC, Chroma, vb.)\n",
    "mfcc = librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=40)  # 40 MFCC özelliği\n",
    "mfcc_mean = np.mean(mfcc, axis=1)  # MFCC'nin ortalamasını al\n",
    "mfcc_std = np.std(mfcc, axis=1)    # MFCC'nin standart sapmasını al\n",
    "\n",
    "# Chroma özellikleri\n",
    "chroma = librosa.feature.chroma_stft(y=audio, sr=16000)\n",
    "chroma_mean = np.mean(chroma, axis=1)\n",
    "\n",
    "# RMS (Root Mean Square) enerji\n",
    "rms = librosa.feature.rms(y=audio)\n",
    "rms_mean = np.mean(rms)\n",
    "\n",
    "# Özellikleri doğru sırayla birleştirelim (52 özellik)\n",
    "features = np.concatenate((\n",
    "    mfcc_mean[2:19],   # MFCC_3'ten MFCC_19'a kadar (index 2-18)\n",
    "    mfcc_mean[21:25],  # MFCC_21'den MFCC_24'e kadar (index 21-24)\n",
    "    mfcc_mean[26:28],  # MFCC_27 ve MFCC_28 (index 26-27)\n",
    "    mfcc_mean[34:40],  # MFCC_35'ten MFCC_40'a kadar (index 34-39)\n",
    "    mfcc_std[1:2],     # MFCC_Std_2 (index 1)\n",
    "    mfcc_std[2:4],     # MFCC_Std_3 ve MFCC_Std_4 (index 2-3)\n",
    "    mfcc_std[4:6],     # MFCC_Std_5 ve MFCC_Std_6 (index 4-5)\n",
    "    mfcc_std[7:8],     # MFCC_Std_8 (index 7)\n",
    "    mfcc_std[9:11],    # MFCC_Std_10 ve MFCC_Std_11 (index 9-10)\n",
    "    mfcc_std[11:13],   # MFCC_Std_12 ve MFCC_Std_13 (index 11-12)\n",
    "    mfcc_std[13:15],   # MFCC_Std_14 ve MFCC_Std_15 (index 13-14)\n",
    "    chroma_mean[:5],   # Chroma_1'den Chroma_5'e kadar (index 0-4)\n",
    "    chroma_mean[6:10], # Chroma_7'den Chroma_10'a kadar (index 6-9)\n",
    "    [rms_mean]         # RMS özelliği\n",
    "))\n",
    "\n",
    "# Özellik vektörünün uzunluğunu kontrol edelim\n",
    "print(\"Feature vector length:\", len(features))  # Bu 52 olmalı\n",
    "\n",
    "# Özellikleri normalize etme\n",
    "scaler = MinMaxScaler()\n",
    "features_normalized = scaler.fit_transform(features.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Özelliklerin doğru formatta (1, 52) olduğundan emin olalım\n",
    "features_normalized = features_normalized.reshape(1, -1)\n",
    "\n",
    "# Modelle tahmin yapma\n",
    "prediction = model.predict(features_normalized)\n",
    "print(f\"Predicted label: {prediction[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BTK-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
