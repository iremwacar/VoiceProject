{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konuşmaya başlayabilirsiniz. Susunca tahmin yapılacak...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iremm\\.conda\\envs\\BTK-AI\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 97 features, but KNeighborsClassifier is expecting 98 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 86\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTahmin Edilen Kişi: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_person\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 86\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 81\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     78\u001b[0m features_normalized \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform([features])\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Tahmin yap\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m predicted_label \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_normalized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m predicted_person \u001b[38;5;241m=\u001b[39m map_label_to_person(predicted_label)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTahmin Edilen Kişi: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_person\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\iremm\\.conda\\envs\\BTK-AI\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:271\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\iremm\\.conda\\envs\\BTK-AI\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:825\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    823\u001b[0m         X \u001b[38;5;241m=\u001b[39m _check_precomputed(X)\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n",
      "File \u001b[1;32mc:\\Users\\iremm\\.conda\\envs\\BTK-AI\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\iremm\\.conda\\envs\\BTK-AI\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 97 features, but KNeighborsClassifier is expecting 98 features as input."
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import joblib\n",
    "import noisereduce as nr  # Gürültü azaltma için\n",
    "\n",
    "# Modeli ve scaler'ı yükle\n",
    "model = joblib.load(\"../Deneme/VoiceModel.pkl\")\n",
    "scaler = joblib.load(\"../Deneme/Scaler.pkl\")  # Eğitilen scaler\n",
    "\n",
    "# Tahmin için kullanılacak etiketler\n",
    "labels = ['elif','irem','nazlı']  # Eğitim sırasında kullanılan kişi isimleri\n",
    "\n",
    "# Etiket eşleştirme fonksiyonu\n",
    "def map_label_to_person(predicted_label):\n",
    "    return labels[predicted_label[0]]\n",
    "\n",
    "# Özellik çıkarma fonksiyonu\n",
    "def extract_features_from_audio(y, sr):\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    mfcc_std = np.std(mfcc, axis=1)\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_mean = np.mean(chroma, axis=1)\n",
    "\n",
    "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
    "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y))\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=y))\n",
    "    rms = np.mean(librosa.feature.rms(y=y))\n",
    "\n",
    "    # Özellikleri birleştir\n",
    "    features = np.concatenate([mfcc_mean, mfcc_std, chroma_mean, \n",
    "                                [spectral_centroid, spectral_bandwidth, spectral_rolloff, zcr, rms]])\n",
    "    return features\n",
    "\n",
    "# Ses toplama fonksiyonu\n",
    "def collect_audio():\n",
    "    print(\"Konuşmaya başlayabilirsiniz. Susunca tahmin yapılacak...\")\n",
    "    duration = 0  # Ses uzunluğu\n",
    "    silence_threshold = 0.02  # Sessizlik eşiği (0 ile 1 arasında)\n",
    "    buffer = []\n",
    "    sr = 16000  # Sabit örnekleme oranı\n",
    "\n",
    "    def callback(indata, frames, time, status):\n",
    "        nonlocal buffer, duration\n",
    "        if status:\n",
    "            print(f\"Durum: {status}\")\n",
    "        audio_chunk = indata[:, 0]\n",
    "        rms = np.sqrt(np.mean(audio_chunk**2))  # RMS ile gürültü seviyesi ölçümü\n",
    "        if rms > silence_threshold:\n",
    "            buffer.extend(audio_chunk)\n",
    "            duration += frames / sr\n",
    "        elif len(buffer) > 0:  # Sessizlik algılanınca dur\n",
    "            raise sd.CallbackStop()\n",
    "\n",
    "    with sd.InputStream(callback=callback, channels=1, samplerate=sr, blocksize=sr):\n",
    "        try:\n",
    "            sd.sleep(6000)  # Maksimum 60 saniye dinleme\n",
    "        except sd.CallbackStop:\n",
    "            pass\n",
    "\n",
    "    return np.array(buffer), sr\n",
    "\n",
    "# Ana tahmin fonksiyonu\n",
    "def main():\n",
    "    # Ses toplama\n",
    "    audio_data, sr = collect_audio()\n",
    "\n",
    "    # Gürültü azaltma\n",
    "    reduced_noise = nr.reduce_noise(y=audio_data, sr=sr)\n",
    "\n",
    "    # Özellik çıkarma\n",
    "    features = extract_features_from_audio(reduced_noise, sr)\n",
    "\n",
    "    # Özellikleri normalize et\n",
    "    features_normalized = scaler.transform([features])\n",
    "\n",
    "    # Tahmin yap\n",
    "    predicted_label = model.predict(features_normalized)\n",
    "    predicted_person = map_label_to_person(predicted_label)\n",
    "    print(f\"Tahmin Edilen Kişi: {predicted_person}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BTK-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
